{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === Import Libraries ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# Evaluation metrics from scikit-learn\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, accuracy_score, average_precision_score\n",
    "# PyTorch Geometric modules for graph data handling\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "# PyTorch modules for model layers and loss functions\n",
    "from torch.nn import BCEWithLogitsLoss, Linear, ModuleDict, LeakyReLU\n",
    "import torch.nn.functional as F\n",
    "# Preprocessing and utility libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# %% === Reproducibility: Set Random Seed for Determinism ===\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True  # Ensures consistent behavior\n",
    "torch.backends.cudnn.benchmark = False  # Disables dynamic kernel optimization for reproducibility"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f010b63680e3279"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %% === Load Node and Edge Data ===\n",
    "nodes = pd.read_csv(\"nodes.tsv\", sep=\"\\t\") # Load node metadata\n",
    "edges = pd.read_csv(\"edges.tsv\", sep=\"\\t\") # Load edge list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e817870d96d80630"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %% === Clean and Preprocess String Fields ===\n",
    "# Strip whitespace from node and edge identifiers to ensure consistency\n",
    "edges[\"source\"] = edges[\"source\"].str.strip()\n",
    "edges[\"target\"] = edges[\"target\"].str.strip()\n",
    "edges[\"metaedge\"] = edges[\"metaedge\"].str.strip()\n",
    "nodes[\"id\"] = nodes[\"id\"].str.strip()\n",
    "# %% === Encode Node and Edge Categories ===\n",
    "# Encode node types (e.g., gene, drug) into integer labels\n",
    "le_node_kind = LabelEncoder()\n",
    "nodes['kind_encoded'] = le_node_kind.fit_transform(nodes['kind'])\n",
    "# Encode edge types (e.g., CbG, CrC) into integer labels\n",
    "le_metaedge = LabelEncoder()\n",
    "edges['metaedge_encoded'] = le_metaedge.fit_transform(edges['metaedge'])\n",
    "# %% === Filter Nodes to Only Include Those Present in Edges ===\n",
    "# Create a set of active node IDs that appear as source or target in edges\n",
    "active_nodes = set(edges[\"source\"]).union(set(edges[\"target\"]))\n",
    "# Filter nodes DataFrame to include only those involved in at least one edge\n",
    "nodes = nodes[nodes[\"id\"].isin(active_nodes)].reset_index(drop=True)\n",
    "# %% === Create Mapping from Node ID to Node Index ===\n",
    "# This will be used to map string-based node IDs to integer indices \n",
    "node_id_map = {node_id: idx for idx, node_id in enumerate(nodes[\"id\"].unique())}\n",
    "num_nodes = len(node_id_map) # Total number of active nodes\n",
    "\n",
    "# %% === Construct compatible Edge Index Tensor ===\n",
    "# Create edge_index with shape [2, num_edges], where each column is [source, target]\n",
    "edge_index = torch.tensor([[node_id_map[src], node_id_map[tgt]] for src, tgt in zip(edges[\"source\"], edges[\"target\"]) if src in active_nodes and tgt in active_nodes], dtype=torch.long).t()\n",
    "# %% === Construct Edge Attribute Tensor ===\n",
    "# Each edge gets an integer attribute corresponding to its metaedge (type)\n",
    "edge_attr = torch.tensor(edges[edges[\"source\"].isin(active_nodes) & edges[\"target\"].isin(active_nodes)]['metaedge_encoded'].values, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8825bf5bf5aa865"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# === Function to Ensure edge_index and edge_attr Are Aligned ===\n",
    "def ensure_alignment(edge_index, edge_attr):\n",
    "        # Ensure that each edge has a corresponding edge attribute\n",
    "    if edge_index.size(1) != edge_attr.size(0):\n",
    "        raise ValueError(\"edge_index and edge_attr must have matching dimensions.\")\n",
    "    # Sort edges by source node for consistent ordering\n",
    "    sorted_idx = edge_index[0].argsort()\n",
    "    edge_index = edge_index[:, sorted_idx]\n",
    "    edge_attr = edge_attr[sorted_idx]\n",
    "    # Final check after sorting\n",
    "    assert edge_index.size(1) == edge_attr.size(0), \"Mismatch after sorting edge_index and edge_attr.\"\n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c0b8cfbd6db9676"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %% === Align edge tensors ===\n",
    "edge_index, edge_attr = ensure_alignment(edge_index, edge_attr)\n",
    "# Initialize node features with Xavier-uniform random values (128 dims)\n",
    "node_features = torch.nn.init.xavier_uniform_(torch.rand(num_nodes, 128))\n",
    "# One-hot encode node types based on their encoded 'kind'\n",
    "kind_embeddings = torch.eye(len(le_node_kind.classes_))[nodes['kind_encoded']].float()\n",
    "kind_embeddings = kind_embeddings[:node_features.size(0)]\n",
    "# Concatenate structural features with node kind embeddings\n",
    "node_features = torch.cat([node_features, kind_embeddings], dim=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba244bc087556bd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Multi-Task GraphSAGE Model\n",
    "class MultiTaskGraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, task_outputs, num_edge_types):\n",
    "        super(MultiTaskGraphSAGE, self).__init__()\n",
    "        # Two-layer GraphSAGE encoder with mean aggregation\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim, aggr='mean', bias=True)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim, aggr='mean', bias=True)\n",
    "        # Learnable embeddings for edge types\n",
    "        self.edge_type_embeddings = torch.nn.Embedding(num_edge_types, hidden_dim)\n",
    "        # Task-specific prediction heads (each task has a separate MLP)\n",
    "        self.task_heads = ModuleDict({task: torch.nn.Sequential(\n",
    "            Linear(hidden_dim * 3, hidden_dim),\n",
    "            LeakyReLU(negative_slope=0.2),\n",
    "            Linear(hidden_dim, output_dim),\n",
    "        ) for task, output_dim in task_outputs.items()\n",
    "        })\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.leaky_relu = LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Two GraphSAGE convolutional layers with LeakyReLU and dropout\n",
    "        x = self.leaky_relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(self.leaky_relu(self.conv2(x, edge_index)))\n",
    "        # Incorporate global edge-type bias into node embeddings\n",
    "        edge_bias = self.edge_type_embeddings(edge_attr).mean(dim=0)\n",
    "        x = x + edge_bias\n",
    "        return x\n",
    "\n",
    "    def predict(self, embeddings, edge_pairs, edge_attr, task):\n",
    "        # Predict scores for given edges and a specific task\n",
    "        assert edge_pairs.size(1) == edge_attr.size(0)\n",
    "        src_embeddings = embeddings[edge_pairs[0]]\n",
    "        tgt_embeddings = embeddings[edge_pairs[1]]\n",
    "        edge_type_emb = self.edge_type_embeddings(edge_attr)\n",
    "        # Concatenate source, target, and edge type embeddings\n",
    "        concat_embeddings = torch.cat([src_embeddings, tgt_embeddings, edge_type_emb], dim=1)\n",
    "        # Pass through task-specific prediction head\n",
    "        output = self.task_heads[task](concat_embeddings)\n",
    "        return torch.sigmoid(output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6089f7cc7536144a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Teacher Model (inherits MultiTaskGraphSAGE)\n",
    "class TeacherModel(MultiTaskGraphSAGE):\n",
    "    def __init__(self, input_dim, hidden_dim, task_outputs, num_edge_types):\n",
    "        super(TeacherModel, self).__init__(input_dim, hidden_dim, task_outputs, num_edge_types)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c28c3a68b5bd94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Student Model (lightweight version of Teacher Model)\n",
    "class StudentModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, task_outputs, num_edge_types):\n",
    "        super(StudentModel, self).__init__()\n",
    "        # Single GraphSAGE layer for lighter computation\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim, aggr='mean', bias=True)\n",
    "        # Edge type embeddings\n",
    "        self.edge_type_embeddings = torch.nn.Embedding(num_edge_types, hidden_dim)\n",
    "        # Task-specific prediction heads\n",
    "        self.task_heads = ModuleDict({\n",
    "            task: torch.nn.Sequential(\n",
    "                Linear(hidden_dim * 3, hidden_dim),\n",
    "                LeakyReLU(negative_slope=0.2),\n",
    "                Linear(hidden_dim, output_dim),\n",
    "            ) for task, output_dim in task_outputs.items()\n",
    "        })\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Apply one GraphSAGE convolution layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # Apply mean edge-type bias to node embeddings\n",
    "        edge_bias = self.edge_type_embeddings(edge_attr).mean(dim=0)\n",
    "        x = x + edge_bias\n",
    "        return x\n",
    "\n",
    "    def predict(self, embeddings, edge_pairs, edge_attr, task):\n",
    "        # Predict edge probabilities for a given task\n",
    "        src_embeddings = embeddings[edge_pairs[0]]\n",
    "        tgt_embeddings = embeddings[edge_pairs[1]]\n",
    "        edge_type_emb = self.edge_type_embeddings(edge_attr)\n",
    "        concat_embeddings = torch.cat([src_embeddings, tgt_embeddings, edge_type_emb], dim=1)\n",
    "        output = self.task_heads[task](concat_embeddings)\n",
    "        return torch.sigmoid(output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18687165020c1311"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Weighted Binary Cross Entropy Loss Wrapper\n",
    "class WeightedBCEWithLogitsLoss(torch.nn.Module):\n",
    "    def __init__(self, pos_weight=None):\n",
    "        super(WeightedBCEWithLogitsLoss, self).__init__()\n",
    "        self.criterion = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        return self.criterion(inputs, targets)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18571bf98f6edda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Knowledge Distillation Loss using KL Divergence\n",
    "def distillation_loss(y_student, y_teacher, temperature_initial=2.0, annealing_rate=0.9):\n",
    "    # Adjust temperature for softening probabilities\n",
    "    temperature = temperature_initial * annealing_rate\n",
    "    # Compute soft targets from teacher outputs\n",
    "    soft_targets = F.softmax(y_teacher / temperature, dim=-1)\n",
    "    # Compute log probabilities for student outputs\n",
    "    student_log_probs = F.log_softmax(y_student / temperature, dim=-1)\n",
    "    # KL divergence loss scaled by squared temperature (standard in KD)\n",
    "    loss = F.kl_div(student_log_probs, soft_targets, reduction='batchmean') * (temperature ** 2)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b353d8abbfce4882"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_negative_edges(edge_index, num_neg_samples, num_nodes):\n",
    "    \"\"\"\n",
    "    Samples a set of negative edges (non-existent links) by randomly choosing \n",
    "    node pairs that are not already connected in the edge_index.\n",
    "    \n",
    "    Args:\n",
    "        edge_index: Edge indices tensor.\n",
    "        num_neg_samples: Number of negative samples to generate.\n",
    "        num_nodes: Total number of nodes in the graph.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Negative edge indices.\n",
    "    \"\"\"\n",
    "    existing = set((i.item(), j.item()) for i, j in zip(*edge_index))\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < num_neg_samples:\n",
    "        src = torch.randint(0, num_nodes, (num_neg_samples,))\n",
    "        dst = torch.randint(0, num_nodes, (num_neg_samples,))\n",
    "        candidates = set((s.item(), d.item()) for s, d in zip(src, dst) if s != d)\n",
    "        new_samples = candidates - existing - neg_edges\n",
    "        neg_edges.update(list(new_samples)[:num_neg_samples - len(neg_edges)])\n",
    "    return torch.tensor(list(neg_edges), dtype=torch.long).T"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "110c9fcf9bddebac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class WeightedLossCombiner(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Combines task loss and distillation loss using a weighted sum.\n",
    "    \n",
    "    Args:\n",
    "        alpha (float): Weight for task loss.\n",
    "        beta (float): Weight for distillation loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.3, beta=0.7):\n",
    "        super(WeightedLossCombiner, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, loss, dist_loss):\n",
    "        return self.alpha * loss + self.beta * dist_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a20988d9a7589440"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def batch_sampling(edge_pairs, edge_attr, batch_size, device):\n",
    "    \"\"\"\n",
    "    Randomly samples a mini-batch of edge pairs and their corresponding attributes.\n",
    "\n",
    "    Args:\n",
    "        edge_pairs: A tensor for representing source and target node indices for each edge.\n",
    "        edge_attr: A tensor containing attributes for each edge.\n",
    "        batch_size: The number of edges to sample in the mini-batch.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Tensor, Tensor]: A tuple containing:\n",
    "            - edge_pairs_sampled: Sampled edge indices of shape.\n",
    "            - edge_attr_sampled: Sampled edge attributes of shape.\n",
    "    \"\"\"\n",
    "    num_edges = edge_pairs.size(1)\n",
    "    indices = torch.randperm(num_edges)[:batch_size]\n",
    "    return edge_pairs[:, indices].to(device), edge_attr[indices].to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86c3d477ecd0dcf5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(edge_index, edge_attr, val_ratio=0.2, test_ratio=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the input edge list and associated attributes into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "        edge_index: A tensor representing the source and target nodes of N edges.\n",
    "        edge_attr: A tensor containing attributes associated with each edge.\n",
    "        val_ratio: The proportion of edges to use for validation.\n",
    "        test_ratio: The proportion of edges to use for testing.\n",
    "        random_state: Seed for reproducible random splitting (default: 42).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing 'train', 'val', and 'test' splits. \n",
    "              Each split is a dictionary with:\n",
    "                  - 'edge_index': A tensor of edge indices for the split.\n",
    "                  - 'edge_attr': A tensor of corresponding edge attributes for the split.\n",
    "\n",
    "    Notes:\n",
    "        - The training set is sampled first, and the remaining edges are then split into validation and test sets.\n",
    "        - The splitting is stratified only by edge indices, not by label or edge type.\n",
    "    \"\"\"\n",
    "    num_edges = edge_index.size(1)\n",
    "    edge_ids = torch.arange(num_edges).tolist()\n",
    "    train_ids, remaining_ids = train_test_split(edge_ids, test_size=val_ratio + test_ratio, random_state=random_state)\n",
    "    val_size = val_ratio / (val_ratio + test_ratio)\n",
    "    val_ids, test_ids = train_test_split(remaining_ids, test_size=1 - val_size, random_state=random_state)\n",
    "    split = {\n",
    "        'train': {\n",
    "            'edge_index': edge_index[:, train_ids],\n",
    "            'edge_attr': edge_attr[train_ids],},\n",
    "        'val': {\n",
    "            'edge_index': edge_index[:, val_ids],\n",
    "            'edge_attr': edge_attr[val_ids],},\n",
    "        'test': {\n",
    "            'edge_index': edge_index[:, test_ids],\n",
    "            'edge_attr': edge_attr[test_ids],}\n",
    "    }\n",
    "\n",
    "    return split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fc78ed33f7cd82e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "split = split_data(edge_index, edge_attr, val_ratio=val_ratio, test_ratio=test_ratio)\n",
    "\n",
    "train_edge_index = split['train']['edge_index']\n",
    "train_edge_attr = split['train']['edge_attr']\n",
    "val_edge_index = split['val']['edge_index']\n",
    "val_edge_attr = split['val']['edge_attr']\n",
    "test_edge_index = split['test']['edge_index']\n",
    "test_edge_attr = split['test']['edge_attr']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57b102d744146d0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_teacher(model, node_features, train_edge_index, train_edge_attr, task_edges, optimizer, criterion, num_nodes, device, batch_size, iterations=10):\n",
    "    \"\"\"\n",
    "    Trains the teacher model for multi-task link prediction over a knowledge graph.\n",
    "\n",
    "    This function performs supervised training using positive and sampled negative edges for each task. \n",
    "    For each batch, it computes the model outputs, constructs labels, and calculates the classification loss.\n",
    "    The loss is aggregated across tasks and iterations, and model parameters are updated via backpropagation.\n",
    "\n",
    "    Args:\n",
    "        model: The teacher model used to generate embeddings and task-specific predictions.\n",
    "        node_features: Input node feature matrix.\n",
    "        train_edge_index: Edge index tensor for training.\n",
    "        train_edge_attr: Edge attributes tensor.\n",
    "        task_edges: Dictionary mapping each task name to a dictionary containing task-specific edge sets, including the 'train' key.\n",
    "        optimizer: Optimizer for updating the model's parameters.\n",
    "        criterion: Binary classification loss function.\n",
    "        batch_size: Number of edge samples in each training batch.\n",
    "        iterations: Number of full training iterations (default: 10).\n",
    "\n",
    "    Returns:\n",
    "        float: The average total loss across all iterations.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for _ in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(node_features, train_edge_index, train_edge_attr)\n",
    "        total_loss = 0\n",
    "        for task, edges in task_edges.items():\n",
    "            positive_pairs = edges['train'].to(device)\n",
    "            edge_attr = train_edge_attr[positive_pairs[0]].to(device)\n",
    "\n",
    "            task_loss = 0\n",
    "            for start in range(0, positive_pairs.size(1), batch_size):\n",
    "                batch_pos_pairs = positive_pairs[:, start:start + batch_size]\n",
    "                batch_edge_attr = edge_attr[start:start + batch_size]\n",
    "                batch_neg_pairs = sample_negative_edges(batch_pos_pairs, batch_pos_pairs.size(1), num_nodes).to(device)\n",
    "                pos_out = model.predict(embeddings, batch_pos_pairs, batch_edge_attr, task)\n",
    "                neg_out = model.predict(embeddings, batch_neg_pairs, batch_edge_attr, task)\n",
    "                all_out = torch.cat([pos_out, neg_out])\n",
    "                all_labels = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "                criterion.pos_weight = torch.tensor([neg_out.size(0) / pos_out.size(0)]).to(device)\n",
    "                loss = criterion(all_out, all_labels)\n",
    "                task_loss += loss\n",
    "            task_loss.backward(retain_graph=True)\n",
    "            total_loss += task_loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / iterations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e49d072e9552ab6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_student(model, teacher_model, node_features, train_edge_index, train_edge_attr, task_edges, optimizer, criterion, distillation_criterion, num_nodes, device, loss_combiner, batch_size, iterations=10):\n",
    "    \"\"\"\n",
    "    This function performs multi-task training over a knowledge graph using a combination of \n",
    "    supervised learning (classification loss) and distillation loss from the teacher model.\n",
    "\n",
    "    Args:\n",
    "        model: The student model to be trained.\n",
    "        teacher_model: The teacher model used for distillation.\n",
    "        node_features: Input node feature matrix.\n",
    "        train_edge_index: Edge index tensor for training.\n",
    "        train_edge_attr: Edge attributes tensor.\n",
    "        task_edges: Dictionary mapping each task name to a dictionary containing task-specific 'train' edge index tensors.\n",
    "        optimizer: Optimizer for the student model.\n",
    "        criterion: Binary classification loss function.\n",
    "        distillation_criterion: Loss function measuring divergence between student and teacher predictions.\n",
    "        loss_combiner: Function to combine task and distillation losses.\n",
    "        batch_size: Number of edge samples per training batch.\n",
    "        iterations: Number of training iterations (default: 10).\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss across all tasks and training iterations.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    teacher_model.eval()\n",
    "    for _ in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(node_features, train_edge_index, train_edge_attr)\n",
    "        \n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            teacher_embeddings = teacher_model(node_features, train_edge_index, train_edge_attr)\n",
    "\n",
    "        for task, edges in task_edges.items():\n",
    "            positive_pairs = edges['train'].to(device)\n",
    "            edge_attr = train_edge_attr[positive_pairs[0]].to(device)\n",
    "            task_loss = 0\n",
    "            for start in range(0, positive_pairs.size(1), batch_size):\n",
    "                batch_pos_pairs = positive_pairs[:, start:start + batch_size]\n",
    "                batch_edge_attr = edge_attr[start:start + batch_size]\n",
    "                batch_neg_pairs = sample_negative_edges(batch_pos_pairs, batch_pos_pairs.size(1), num_nodes).to(device)\n",
    "                pos_out = model.predict(embeddings, batch_pos_pairs, batch_edge_attr, task)\n",
    "                neg_out = model.predict(embeddings, batch_neg_pairs, batch_edge_attr, task)\n",
    "                \n",
    "                all_out = torch.cat([pos_out, neg_out])\n",
    "                all_labels = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "                criterion.pos_weight = torch.tensor([neg_out.size(0) / pos_out.size(0)]).to(device)\n",
    "                loss_task = criterion(all_out, all_labels)\n",
    "                with torch.no_grad():\n",
    "                    teacher_pos_out = teacher_model.predict(teacher_embeddings, batch_pos_pairs, batch_edge_attr, task)\n",
    "                    teacher_neg_out = teacher_model.predict(teacher_embeddings, batch_neg_pairs, batch_edge_attr, task)\n",
    "                    teacher_out = torch.cat([teacher_pos_out, teacher_neg_out])\n",
    "\n",
    "                loss_distill = distillation_criterion(all_out, teacher_out)\n",
    "                combined_loss = loss_combiner(loss_task, loss_distill)\n",
    "                task_loss += combined_loss\n",
    "            task_loss.backward(retain_graph=True)\n",
    "            total_loss += task_loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / iterations  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8c59b183cf8256a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_model(model, node_features, val_edge_index, val_edge_attr, task_edges, num_nodes, iterations=10):\n",
    "    \"\"\"\n",
    "    Evaluates a trained model on validation edges for each task using multiple performance metrics.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model to evaluate.\n",
    "        node_features: Node feature matrix.\n",
    "        val_edge_index: Edge index tensor for the validation graph.\n",
    "        val_edge_attr: Edge attribute tensor for the validation edges.\n",
    "        task_edges: Dictionary mapping each task name to a dictionary containing task-specific edge splits (including 'val').\n",
    "        iterations: Number of evaluation repetitions for robust metrics (default: 10).\n",
    "\n",
    "    Returns:\n",
    "        Dict: Dictionary mapping each task to a dictionary of aggregated metrics:\n",
    "            - auc_mean / auc_std\n",
    "            - aupr_mean / aupr_std\n",
    "            - accuracy_mean / accuracy_std\n",
    "            - f1_mean / f1_std\n",
    "            - precision_mean / precision_std\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_metrics = {task: {'auc': [], 'aupr': [], 'accuracy': [], 'f1': [], 'precision': []} for task in task_edges}\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(node_features, val_edge_index, val_edge_attr)\n",
    "            for task, edges in task_edges.items():\n",
    "                edge_split = edges['val'].to(device)\n",
    "                edge_attr = val_edge_attr[edge_split[0]].to(device)\n",
    "                pos_out = model.predict(embeddings, edge_split, edge_attr, task)\n",
    "                neg_edges = sample_negative_edges(edge_split, edge_split.size(1), num_nodes)\n",
    "                neg_attr = edge_attr[neg_edges[0]]\n",
    "                neg_out = model.predict(embeddings, neg_edges, neg_attr, task)\n",
    "                preds = np.concatenate([pos_out, neg_out])\n",
    "                labels = np.concatenate([np.ones_like(pos_out), np.zeros_like(neg_out)])\n",
    "                binary_preds = (preds >= 0.5).astype(int)\n",
    "                auc = roc_auc_score(labels, preds) if len(np.unique(labels)) > 1 else 0.0\n",
    "                aupr = average_precision_score(labels, preds) if len(np.unique(labels)) > 1 else 0.0\n",
    "                accuracy = accuracy_score(labels, binary_preds)\n",
    "                f1 = f1_score(labels, binary_preds)\n",
    "                precision = precision_score(labels, binary_preds, zero_division=1)\n",
    "                all_metrics[task]['auc'].append(auc)\n",
    "                all_metrics[task]['aupr'].append(aupr)\n",
    "                all_metrics[task]['accuracy'].append(accuracy)\n",
    "                all_metrics[task]['f1'].append(f1)\n",
    "                all_metrics[task]['precision'].append(precision)\n",
    "    final_metrics = {}\n",
    "    for task, metrics in all_metrics.items():\n",
    "        final_metrics[task] = {\n",
    "            'auc_mean': np.mean(metrics['auc']),\n",
    "            'auc_std': np.std(metrics['auc']),\n",
    "            'aupr_mean': np.mean(metrics['aupr']),\n",
    "            'aupr_std': np.std(metrics['aupr']),\n",
    "            'accuracy_mean': np.mean(metrics['accuracy']),\n",
    "            'accuracy_std': np.std(metrics['accuracy']),\n",
    "            'f1_mean': np.mean(metrics['f1']),\n",
    "            'f1_std': np.std(metrics['f1']),\n",
    "            'precision_mean': np.mean(metrics['precision']),\n",
    "            'precision_std': np.std(metrics['precision']),\n",
    "        }\n",
    "\n",
    "    return final_metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e13c1cdae37167"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_model(model, node_features, test_edge_index, test_edge_attr, task_edges, num_nodes, iterations=10):\n",
    "    model.eval()\n",
    "    all_metrics = {task: {'auc': [], 'aupr': [], 'accuracy': [], 'f1': [], 'precision': []} for task in task_edges}\n",
    "    inference_times = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        start_time = time.time() \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeddings = model(node_features, test_edge_index, test_edge_attr)\n",
    "            for task, edges in task_edges.items():\n",
    "                edge_split = edges['test'].to(device)\n",
    "                edge_attr = test_edge_attr[edge_split[0]].to(device)\n",
    "                pos_out = model.predict(embeddings, edge_split, edge_attr, task)\n",
    "                neg_edges = sample_negative_edges(edge_split, edge_split.size(1), num_nodes)\n",
    "                neg_attr = edge_attr[neg_edges[0]]\n",
    "                neg_out = model.predict(embeddings, neg_edges, neg_attr, task)\n",
    "                preds = np.concatenate([pos_out, neg_out])\n",
    "                labels = np.concatenate([np.ones_like(pos_out), np.zeros_like(neg_out)])\n",
    "                binary_preds = (preds >= 0.5).astype(int)\n",
    "                auc = roc_auc_score(labels, preds) if len(np.unique(labels)) > 1 else 0.0\n",
    "                aupr = average_precision_score(labels, preds) if len(np.unique(labels)) > 1 else 0.0\n",
    "                accuracy = accuracy_score(labels, binary_preds)\n",
    "                f1 = f1_score(labels, binary_preds)\n",
    "                precision = precision_score(labels, binary_preds, zero_division=1)\n",
    "                all_metrics[task]['auc'].append(auc)\n",
    "                all_metrics[task]['aupr'].append(aupr)\n",
    "                all_metrics[task]['accuracy'].append(accuracy)\n",
    "                all_metrics[task]['f1'].append(f1)\n",
    "                all_metrics[task]['precision'].append(precision)\n",
    "        end_time = time.time()  \n",
    "        inference_times.append(end_time - start_time)  \n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    std_inference_time = np.std(inference_times)\n",
    "    final_metrics = {}\n",
    "    for task, metrics in all_metrics.items():\n",
    "        final_metrics[task] = {\n",
    "            'auc_mean': np.mean(metrics['auc']),\n",
    "            'auc_std': np.std(metrics['auc']),\n",
    "            'aupr_mean': np.mean(metrics['aupr']),\n",
    "            'aupr_std': np.std(metrics['aupr']),\n",
    "            'accuracy_mean': np.mean(metrics['accuracy']),\n",
    "            'accuracy_std': np.std(metrics['accuracy']),\n",
    "            'f1_mean': np.mean(metrics['f1']),\n",
    "            'f1_std': np.std(metrics['f1']),\n",
    "            'precision_mean': np.mean(metrics['precision']),\n",
    "            'precision_std': np.std(metrics['precision']),\n",
    "        }\n",
    "\n",
    "    final_metrics['inference_time'] = {\n",
    "        'avg_inference_time': avg_inference_time,\n",
    "        'std_inference_time': std_inference_time,}\n",
    "\n",
    "    return final_metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccac8202f2576978"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tasks = [\"CaD\", \"CrC\", \"CbG\", \"DaG\"]\n",
    "\n",
    "task_edges = {}\n",
    "\n",
    "for task in tasks:\n",
    "    task_edges[task] = {\n",
    "        'train': train_edge_index.clone(),\n",
    "        'val': val_edge_index.clone(),\n",
    "        'test': test_edge_index.clone(),\n",
    "    }\n",
    "\n",
    "hidden_dim_t = 128\n",
    "hidden_dim_s = 64\n",
    "task_outputs = {task: 1 for task in tasks}\n",
    "num_edge_types = len(le_metaedge.classes_)\n",
    "\n",
    "teacher_model = TeacherModel(input_dim=node_features.shape[1], hidden_dim=hidden_dim_t, task_outputs=task_outputs, num_edge_types=num_edge_types).to(device)\n",
    "\n",
    "student_model = StudentModel(input_dim=node_features.shape[1], hidden_dim=hidden_dim_s, task_outputs=task_outputs, num_edge_types=num_edge_types).to(device)\n",
    "\n",
    "criterion = WeightedBCEWithLogitsLoss()\n",
    "\n",
    "optimizer_teacher = torch.optim.Adam(teacher_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "optimizer_student = torch.optim.Adam(student_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "loss_combiner = WeightedLossCombiner().to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d604daf55568e480"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training Teacher Model...\")\n",
    "for epoch in range(epochs):\n",
    "    loss = train_teacher(teacher_model, node_features, train_edge_index, train_edge_attr, task_edges, optimizer_teacher, criterion, num_nodes, device, batch_size, iterations=1)\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        val_metrics = validate_model(teacher_model, node_features, val_edge_index, val_edge_attr, task_edges, 'val', num_nodes, iterations=10)\n",
    "        for task, metric in val_metrics.items():\n",
    "            print(f\"Validation {task}: AUC: {metric['auc_mean']:.4f} ± {metric['auc_std']:.4f}, \"\n",
    "                  f\"AUPR: {metric['aupr_mean']:.4f} ± {metric['aupr_std']:.4f}, \"\n",
    "                  f\"Accuracy: {metric['accuracy_mean']:.4f} ± {metric['accuracy_std']:.4f}, \"\n",
    "                  f\"F1: {metric['f1_mean']:.4f} ± {metric['f1_std']:.4f}, \"\n",
    "                  f\"Precision: {metric['precision_mean']:.4f} ± {metric['precision_std']:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3de9511cb661808"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_metrics = test_model(teacher_model, node_features, test_edge_index, test_edge_attr, task_edges, num_nodes, iterations=10)\n",
    "\n",
    "print(\"\\nTeacher Model Test Results:\")\n",
    "for task, metric in test_metrics.items():\n",
    "        print(f\"Test Result {task}: AUC: {metric['auc_mean']:.4f} ± {metric['auc_std']:.4f}, \"\n",
    "              f\"AUPR: {metric['aupr_mean']:.4f} ± {metric['aupr_std']:.4f}, \"\n",
    "              f\"Accuracy: {metric['accuracy_mean']:.4f} ± {metric['accuracy_std']:.4f}, \"\n",
    "              f\"F1: {metric['f1_mean']:.4f} ± {metric['f1_std']:.4f}, \"\n",
    "              f\"Precision: {metric['precision_mean']:.4f} ± {metric['precision_std']:.4f}\")\n",
    "\n",
    "inference_time = test_metrics['inference_time']\n",
    "avg_inference_time = inference_time['avg_inference_time']\n",
    "std_inference_time = inference_time['std_inference_time']\n",
    "\n",
    "print(f\"\\nAverage Inference Time: {avg_inference_time:.4f} ± {std_inference_time:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d730f6a0150f6f46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\nTraining Student Model WITH Knowledge Distillation...\")\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    loss = train_student(student_model, teacher_model, node_features, train_edge_index, train_edge_attr, task_edges, optimizer_student, criterion, distillation_loss, num_nodes, device, loss_combiner, batch_size, iterations=10)\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        val_metrics = validate_model(student_model, node_features, val_edge_index, val_edge_attr, task_edges, num_nodes, iterations=10)\n",
    "        for task, metric in val_metrics.items():\n",
    "            print(f\"Validation {task}: AUC: {metric['auc_mean']:.4f} ± {metric['auc_std']:.4f}, \"\n",
    "                  f\"AUPR: {metric['aupr_mean']:.4f} ± {metric['aupr_std']:.4f}, \"\n",
    "                  f\"Accuracy: {metric['accuracy_mean']:.4f} ± {metric['accuracy_std']:.4f}, \"\n",
    "                  f\"F1: {metric['f1_mean']:.4f} ± {metric['f1_std']:.4f}, \"\n",
    "                  f\"Precision: {metric['precision_mean']:.4f} ± {metric['precision_std']:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c9e7a19a3608923"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_metrics = test_model(student_model, node_features, test_edge_index, test_edge_attr, task_edges, num_nodes, iterations=10)\n",
    "print(\"\\nStudent Model Test Results:\")\n",
    "for task, metric in test_metrics.items():\n",
    "        print(f\"Test Result {task}: AUC: {metric['auc_mean']:.4f} ± {metric['auc_std']:.4f}, \"\n",
    "              f\"AUPR: {metric['aupr_mean']:.4f} ± {metric['aupr_std']:.4f}, \"\n",
    "              f\"Accuracy: {metric['accuracy_mean']:.4f} ± {metric['accuracy_std']:.4f}, \"\n",
    "              f\"F1: {metric['f1_mean']:.4f} ± {metric['f1_std']:.4f}, \"\n",
    "              f\"Precision: {metric['precision_mean']:.4f} ± {metric['precision_std']:.4f}\")\n",
    "\n",
    "inference_time = test_metrics['inference_time']\n",
    "avg_inference_time = inference_time['avg_inference_time']\n",
    "std_inference_time = inference_time['std_inference_time']\n",
    "\n",
    "print(f\"\\nAverage Inference Time: {avg_inference_time:.4f} ± {std_inference_time:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f4afa0dc8824d5e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
